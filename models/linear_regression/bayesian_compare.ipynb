{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42) # for repeatability \n",
    "theta_true = (25, 0.5)\n",
    "xdata = 100 * np.random.random(20)\n",
    "ydata = theta_true[0] + theta_true[1] * xdata \n",
    "ydata = np.random.normal(ydata, 10) # add error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequentist Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack([np.ones_like(xdata), xdata]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hat = np.linalg.solve(np.dot(X.T, X), np.dot(X.T, ydata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.dot(X, theta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_hat = np.std(ydata - y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma = sigma_hat ** 2 * np.linalg.inv(np.dot(X.T, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Results: Ordinary least squares\n",
      "=================================================================\n",
      "Model:              OLS              Adj. R-squared:     0.683   \n",
      "Dependent Variable: y                AIC:                147.7737\n",
      "Date:               2019-04-07 23:29 BIC:                149.7651\n",
      "No. Observations:   20               Log-Likelihood:     -71.887 \n",
      "Df Model:           1                F-statistic:        41.97   \n",
      "Df Residuals:       18               Prob (F-statistic): 4.30e-06\n",
      "R-squared:          0.700            Scale:              86.157  \n",
      "-------------------------------------------------------------------\n",
      "            Coef.    Std.Err.     t      P>|t|     [0.025    0.975]\n",
      "-------------------------------------------------------------------\n",
      "const      24.6361     3.7871   6.5053   0.0000   16.6797   32.5924\n",
      "x1          0.4483     0.0692   6.4782   0.0000    0.3029    0.5937\n",
      "-----------------------------------------------------------------\n",
      "Omnibus:              1.996        Durbin-Watson:           2.758\n",
      "Prob(Omnibus):        0.369        Jarque-Bera (JB):        1.634\n",
      "Skew:                 0.651        Prob(JB):                0.442\n",
      "Kurtosis:             2.486        Condition No.:           100  \n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = sm.add_constant(xdata)\n",
    "result = sm.OLS(ydata, X).fit()\n",
    "sigma_hat = result.params\n",
    "Sigma = result.cov_params()\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee # version 2.0 \n",
    "\n",
    "def log_prior(theta):\n",
    "    alpha, beta, sigma = theta \n",
    "    if sigma < 0:\n",
    "        return -np.inf # log(0) \n",
    "    else:\n",
    "        return (-1.5 * np.log(1 + beta**2) - np.log(sigma))\n",
    "    \n",
    "def log_like(theta, x, y):\n",
    "    alpha, beta, sigma = theta\n",
    "    y_model = alpha + beta * x\n",
    "    return -0.5 * np.sum(np.log(2*np.pi*sigma**2) + (y-y_model)**2 / sigma**2) \n",
    "\n",
    "def log_posterior(theta, x, y):\n",
    "    return log_prior(theta) + log_like(theta,x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndim = 3 # number of parameters in the model \n",
    "nwalkers = 50 # number of MCMC walkers\n",
    "nburn = 1000 # \"burn-in\" to stabilize chains \n",
    "nsteps = 2000 # number of MCMC steps to take \n",
    "starting_guesses = np.random.rand(nwalkers, ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = emcee.EnsembleSampler(nwalkers, ndim,\n",
    "                                log_posterior,\n",
    "                                args=[xdata,ydata])\n",
    "sampler.run_mcmc(starting_guesses, nsteps)\n",
    "# chain is of shape (nwalkers, nsteps, ndim): # discard burn-in points and reshape:\n",
    "trace = sampler.chain[:, nburn:, :]\n",
    "trace = trace.reshape(-1, ndim).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
